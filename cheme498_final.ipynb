{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CHEM E 498: Final Exam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Due  06/05 at 5:00 pm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note: This is an exam and should represent only your work. Carefully following the code of conduct is critical."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Broad overview of the problem</b> : In this exam, you are using an Infrared (IR) Spectroscopic Imaging data of a patient sample taken by me in the lab. This dataset is a multidimensional data, with x and y positions capturing the spatial coordinates of points on the image and z positions recording the absorption of light at different frequencies in the mid-infrared region of the light. You have two more images supplementing the IR data where the classified image is showing three different cell types in the sample (one in green, one in blue, one in magenta). The green cells are where cancer originates and is also known as epithelial cells, magenta is the one where there are collagen fibers and blue cells are all other cells combined together. The H&E image is the image we get from clinicians that is typically used in hospitals to make a cancer diagnosis. I wanted to give you all an experience to implement the course knowledge on a real dataset with potential human impact. In the homework 4, you implemented unsupervised learning techniques and in the final exam you will apply supervised techniques along with dimensionality reduction. Good Luck! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### General Instructions: you should run every cell of your jupyter notebook and then submit the jupyter notebook so that I can see the output without initially running it. The notebook name should your name. Every graph/plot should be labeled. The code should have comments so that it is easy to follow through what you have done. All the text components should be present as markdown cells in the same jupyter notebook. Wherever a random state needs to be defined to have consistent output across multiple runs, use a random state of 40.  No late submissions will be graded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question1: Plot the non-background pixels (preprocessed data) as a scatter plot of feature 1 vs feature 2 while using the labels to color the observations. Next, theoretically discuss which of the following models [LDA, SVM (linear), SVM (kernel based), Decision Trees and RF] will work better than the others in the list.  (7 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 2: Split your data (preprocessed data with no background pixels) into train and test with 1% of your data going to test. Remove the outliers from the training data based on z-score value of 3. Next, out of the resulting training data, sample only 1% to fit the classification algorithms. Implement [LDA, SVM (linear), SVM (kernel based, rbf), Decision Trees and RF] on this data and output the train and test accuracies ( 8 points). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 3: Identify the top features from the RF model built in Q2. based on feature importance. Use these two features to build a new RF model and optimize it by tuning the following hyperparameters (number of trees, maximum depth and minimum samples at the leaf node). Discuss how the choice of hyperparameters is affecting the accuracy of your model and output the train and test accuracies from your best model (15 points). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 4: Dimensionality Reduction: Apply PCA to your data (as used in Q2.) with a total of two components. Use these components as features in your best model from Q3. Discuss the performance after PCA by looking the test accuracies and the confusion matrices. (10 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
